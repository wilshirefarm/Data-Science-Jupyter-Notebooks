{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tress using `scikit-learn`\n",
    "\n",
    "Scikit-learn provides a range of supervised and unsupervised learning algorithms via a consistent interface in Python. In this assigment you'll explore how to train decision trees using the `scikit-learn` library. The scikit-learn documentation can be found [here](http://scikit-learn.org/stable/documentation.html).\n",
    "\n",
    "In this assignment we'll attempt to classify patients as either having or not having diabetic retinopathy. For this task we'll be using the Diabetic Retinopathy data set, which contains 1151 instances and 20 attributes (some categorical, some continuous). You can find additional details about the dataset [here](http://archive.ics.uci.edu/ml/datasets/Diabetic+Retinopathy+Debrecen+Data+Set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You may add additional import if you want\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>prescreen</th>\n",
       "      <th>ma2</th>\n",
       "      <th>ma3</th>\n",
       "      <th>ma4</th>\n",
       "      <th>ma5</th>\n",
       "      <th>ma6</th>\n",
       "      <th>ma7</th>\n",
       "      <th>exudate8</th>\n",
       "      <th>exudate9</th>\n",
       "      <th>exudate10</th>\n",
       "      <th>exudate11</th>\n",
       "      <th>exudate12</th>\n",
       "      <th>exudate13</th>\n",
       "      <th>exudate14</th>\n",
       "      <th>exudate15</th>\n",
       "      <th>euDist</th>\n",
       "      <th>diameter</th>\n",
       "      <th>amfm_class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>40.467228</td>\n",
       "      <td>18.445954</td>\n",
       "      <td>9.118901</td>\n",
       "      <td>3.079428</td>\n",
       "      <td>0.840261</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>18.026254</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>28.356400</td>\n",
       "      <td>6.935636</td>\n",
       "      <td>2.305771</td>\n",
       "      <td>0.323724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502831</td>\n",
       "      <td>0.126741</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>15.448398</td>\n",
       "      <td>9.113819</td>\n",
       "      <td>1.633493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541743</td>\n",
       "      <td>0.139575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.679649</td>\n",
       "      <td>9.497786</td>\n",
       "      <td>1.223660</td>\n",
       "      <td>0.150382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576318</td>\n",
       "      <td>0.071071</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>66.691933</td>\n",
       "      <td>23.545543</td>\n",
       "      <td>6.151117</td>\n",
       "      <td>0.496372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500073</td>\n",
       "      <td>0.116793</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>22.141784</td>\n",
       "      <td>10.054384</td>\n",
       "      <td>0.874633</td>\n",
       "      <td>0.099780</td>\n",
       "      <td>0.023386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560959</td>\n",
       "      <td>0.109134</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>84.358401</td>\n",
       "      <td>50.977459</td>\n",
       "      <td>17.293722</td>\n",
       "      <td>1.974419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546008</td>\n",
       "      <td>0.112378</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>22.480047</td>\n",
       "      <td>13.949995</td>\n",
       "      <td>0.436232</td>\n",
       "      <td>0.116119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551682</td>\n",
       "      <td>0.139657</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>50</td>\n",
       "      <td>10.560100</td>\n",
       "      <td>3.108358</td>\n",
       "      <td>0.625511</td>\n",
       "      <td>0.287959</td>\n",
       "      <td>0.103985</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.534396</td>\n",
       "      <td>0.089587</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>43</td>\n",
       "      <td>39</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>18</td>\n",
       "      <td>23.012798</td>\n",
       "      <td>6.737583</td>\n",
       "      <td>2.403903</td>\n",
       "      <td>0.189235</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501554</td>\n",
       "      <td>0.138287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "      <td>92</td>\n",
       "      <td>89</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>8.610822</td>\n",
       "      <td>1.981319</td>\n",
       "      <td>0.401183</td>\n",
       "      <td>0.066095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541277</td>\n",
       "      <td>0.124505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quality  prescreen  ma2  ma3  ma4  ma5  ma6  ma7   exudate8   exudate9  \\\n",
       "0         1          1   22   22   22   19   18   14  49.895756  17.775994   \n",
       "1         1          1   24   24   22   18   16   13  57.709936  23.799994   \n",
       "2         1          1   62   60   59   54   47   33  55.831441  27.993933   \n",
       "3         1          1   55   53   53   50   43   31  40.467228  18.445954   \n",
       "4         1          1   44   44   44   41   39   27  18.026254   8.570709   \n",
       "5         1          1   44   43   41   41   37   29  28.356400   6.935636   \n",
       "6         1          0   29   29   29   27   25   16  15.448398   9.113819   \n",
       "7         1          1    6    6    6    6    2    1  20.679649   9.497786   \n",
       "8         1          1   22   21   18   15   13   10  66.691933  23.545543   \n",
       "9         1          1   79   75   73   71   64   47  22.141784  10.054384   \n",
       "10        1          1   45   45   45   43   40   32  84.358401  50.977459   \n",
       "11        1          0   25   25   25   23   22   18  22.480047  13.949995   \n",
       "12        1          1   70   69   65   63   63   50  10.560100   3.108358   \n",
       "13        1          1   48   43   39   32   27   18  23.012798   6.737583   \n",
       "14        1          1   94   93   92   89   86   77   8.610822   1.981319   \n",
       "\n",
       "    exudate10  exudate11  exudate12  exudate13  exudate14  exudate15  \\\n",
       "0    5.270920   0.771761   0.018632   0.006864   0.003923   0.003923   \n",
       "1    3.325423   0.234185   0.003903   0.003903   0.003903   0.003903   \n",
       "2   12.687485   4.852282   1.393889   0.373252   0.041817   0.007744   \n",
       "3    9.118901   3.079428   0.840261   0.272434   0.007653   0.001531   \n",
       "4    0.410381   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5    2.305771   0.323724   0.000000   0.000000   0.000000   0.000000   \n",
       "6    1.633493   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "7    1.223660   0.150382   0.000000   0.000000   0.000000   0.000000   \n",
       "8    6.151117   0.496372   0.000000   0.000000   0.000000   0.000000   \n",
       "9    0.874633   0.099780   0.023386   0.000000   0.000000   0.000000   \n",
       "10  17.293722   1.974419   0.000000   0.000000   0.000000   0.000000   \n",
       "11   0.436232   0.116119   0.000000   0.000000   0.000000   0.000000   \n",
       "12   0.625511   0.287959   0.103985   0.004799   0.000000   0.000000   \n",
       "13   2.403903   0.189235   0.011437   0.000000   0.000000   0.000000   \n",
       "14   0.401183   0.066095   0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "      euDist  diameter  amfm_class  label  \n",
       "0   0.486903  0.100025           1      0  \n",
       "1   0.520908  0.144414           0      0  \n",
       "2   0.530904  0.128548           0      1  \n",
       "3   0.483284  0.114790           0      0  \n",
       "4   0.475935  0.123572           0      1  \n",
       "5   0.502831  0.126741           0      1  \n",
       "6   0.541743  0.139575           0      1  \n",
       "7   0.576318  0.071071           1      0  \n",
       "8   0.500073  0.116793           0      1  \n",
       "9   0.560959  0.109134           0      1  \n",
       "10  0.546008  0.112378           0      0  \n",
       "11  0.551682  0.139657           1      0  \n",
       "12  0.534396  0.089587           0      1  \n",
       "13  0.501554  0.138287           1      1  \n",
       "14  0.541277  0.124505           0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from csv file\n",
    "col_names = []\n",
    "for i in range(20):\n",
    "    if i == 0:\n",
    "        col_names.append('quality')\n",
    "    if i == 1:\n",
    "        col_names.append('prescreen')\n",
    "    if i >= 2 and i <= 7:\n",
    "        col_names.append('ma' + str(i))\n",
    "    if i >= 8 and i <= 15:\n",
    "        col_names.append('exudate' + str(i))\n",
    "    if i == 16:\n",
    "        col_names.append('euDist')\n",
    "    if i == 17:\n",
    "        col_names.append('diameter')\n",
    "    if i == 18:\n",
    "        col_names.append('amfm_class')\n",
    "    if i == 19:\n",
    "        col_names.append('label')\n",
    "\n",
    "data = pd.read_csv(\"messidor_features.txt\", names = col_names)\n",
    "print(data.shape)\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing  & dimensionality reduction with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Separate the feature columns from the class label column. You should end up with two separate data frames (or two lists, or two numpy arrays) - one that contains all of the feature values and one that contains the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>prescreen</th>\n",
       "      <th>ma2</th>\n",
       "      <th>ma3</th>\n",
       "      <th>ma4</th>\n",
       "      <th>ma5</th>\n",
       "      <th>ma6</th>\n",
       "      <th>ma7</th>\n",
       "      <th>exudate8</th>\n",
       "      <th>exudate9</th>\n",
       "      <th>exudate10</th>\n",
       "      <th>exudate11</th>\n",
       "      <th>exudate12</th>\n",
       "      <th>exudate13</th>\n",
       "      <th>exudate14</th>\n",
       "      <th>exudate15</th>\n",
       "      <th>euDist</th>\n",
       "      <th>diameter</th>\n",
       "      <th>amfm_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>40.467228</td>\n",
       "      <td>18.445954</td>\n",
       "      <td>9.118901</td>\n",
       "      <td>3.079428</td>\n",
       "      <td>0.840261</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>18.026254</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>28.356400</td>\n",
       "      <td>6.935636</td>\n",
       "      <td>2.305771</td>\n",
       "      <td>0.323724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502831</td>\n",
       "      <td>0.126741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>15.448398</td>\n",
       "      <td>9.113819</td>\n",
       "      <td>1.633493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541743</td>\n",
       "      <td>0.139575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.679649</td>\n",
       "      <td>9.497786</td>\n",
       "      <td>1.223660</td>\n",
       "      <td>0.150382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576318</td>\n",
       "      <td>0.071071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>66.691933</td>\n",
       "      <td>23.545543</td>\n",
       "      <td>6.151117</td>\n",
       "      <td>0.496372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500073</td>\n",
       "      <td>0.116793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>22.141784</td>\n",
       "      <td>10.054384</td>\n",
       "      <td>0.874633</td>\n",
       "      <td>0.099780</td>\n",
       "      <td>0.023386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560959</td>\n",
       "      <td>0.109134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality  prescreen  ma2  ma3  ma4  ma5  ma6  ma7   exudate8   exudate9  \\\n",
       "0        1          1   22   22   22   19   18   14  49.895756  17.775994   \n",
       "1        1          1   24   24   22   18   16   13  57.709936  23.799994   \n",
       "2        1          1   62   60   59   54   47   33  55.831441  27.993933   \n",
       "3        1          1   55   53   53   50   43   31  40.467228  18.445954   \n",
       "4        1          1   44   44   44   41   39   27  18.026254   8.570709   \n",
       "5        1          1   44   43   41   41   37   29  28.356400   6.935636   \n",
       "6        1          0   29   29   29   27   25   16  15.448398   9.113819   \n",
       "7        1          1    6    6    6    6    2    1  20.679649   9.497786   \n",
       "8        1          1   22   21   18   15   13   10  66.691933  23.545543   \n",
       "9        1          1   79   75   73   71   64   47  22.141784  10.054384   \n",
       "\n",
       "   exudate10  exudate11  exudate12  exudate13  exudate14  exudate15    euDist  \\\n",
       "0   5.270920   0.771761   0.018632   0.006864   0.003923   0.003923  0.486903   \n",
       "1   3.325423   0.234185   0.003903   0.003903   0.003903   0.003903  0.520908   \n",
       "2  12.687485   4.852282   1.393889   0.373252   0.041817   0.007744  0.530904   \n",
       "3   9.118901   3.079428   0.840261   0.272434   0.007653   0.001531  0.483284   \n",
       "4   0.410381   0.000000   0.000000   0.000000   0.000000   0.000000  0.475935   \n",
       "5   2.305771   0.323724   0.000000   0.000000   0.000000   0.000000  0.502831   \n",
       "6   1.633493   0.000000   0.000000   0.000000   0.000000   0.000000  0.541743   \n",
       "7   1.223660   0.150382   0.000000   0.000000   0.000000   0.000000  0.576318   \n",
       "8   6.151117   0.496372   0.000000   0.000000   0.000000   0.000000  0.500073   \n",
       "9   0.874633   0.099780   0.023386   0.000000   0.000000   0.000000  0.560959   \n",
       "\n",
       "   diameter  amfm_class  \n",
       "0  0.100025           1  \n",
       "1  0.144414           0  \n",
       "2  0.128548           0  \n",
       "3  0.114790           0  \n",
       "4  0.123572           0  \n",
       "5  0.126741           0  \n",
       "6  0.139575           0  \n",
       "7  0.071071           1  \n",
       "8  0.116793           0  \n",
       "9  0.109134           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "label = data['label'].to_frame('class label')\n",
    "label.head(10)\n",
    "\n",
    "features = data\n",
    "features = features.drop('label', axis=1)\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Use `sklearn.preprocessing.StandardScaler` to standardize the dataset’s features (mean = 0 and variance = 1). Only standardize the the features, not the class labels! This will be required for running the principal component analysis (PCA) dimensionality reduction later. Note that `StandardScaler` returns a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>prescreen</th>\n",
       "      <th>ma2</th>\n",
       "      <th>ma3</th>\n",
       "      <th>ma4</th>\n",
       "      <th>ma5</th>\n",
       "      <th>ma6</th>\n",
       "      <th>ma7</th>\n",
       "      <th>exudate8</th>\n",
       "      <th>exudate9</th>\n",
       "      <th>exudate10</th>\n",
       "      <th>exudate11</th>\n",
       "      <th>exudate12</th>\n",
       "      <th>exudate13</th>\n",
       "      <th>exudate14</th>\n",
       "      <th>exudate15</th>\n",
       "      <th>euDist</th>\n",
       "      <th>diameter</th>\n",
       "      <th>amfm_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.641486</td>\n",
       "      <td>-0.618782</td>\n",
       "      <td>-0.576463</td>\n",
       "      <td>-0.630029</td>\n",
       "      <td>-0.551116</td>\n",
       "      <td>-0.473745</td>\n",
       "      <td>-0.242917</td>\n",
       "      <td>-0.246003</td>\n",
       "      <td>-0.296966</td>\n",
       "      <td>-0.271509</td>\n",
       "      <td>-0.218324</td>\n",
       "      <td>-0.194409</td>\n",
       "      <td>-0.205124</td>\n",
       "      <td>-0.186169</td>\n",
       "      <td>-1.294763</td>\n",
       "      <td>-0.468656</td>\n",
       "      <td>1.405048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.563391</td>\n",
       "      <td>-0.535778</td>\n",
       "      <td>-0.576463</td>\n",
       "      <td>-0.677410</td>\n",
       "      <td>-0.653676</td>\n",
       "      <td>-0.539992</td>\n",
       "      <td>-0.109250</td>\n",
       "      <td>0.032972</td>\n",
       "      <td>-0.465224</td>\n",
       "      <td>-0.408593</td>\n",
       "      <td>-0.224256</td>\n",
       "      <td>-0.197212</td>\n",
       "      <td>-0.205175</td>\n",
       "      <td>-0.186281</td>\n",
       "      <td>-0.082168</td>\n",
       "      <td>2.006054</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.920417</td>\n",
       "      <td>0.958299</td>\n",
       "      <td>1.046665</td>\n",
       "      <td>1.028299</td>\n",
       "      <td>0.936006</td>\n",
       "      <td>0.784951</td>\n",
       "      <td>-0.141383</td>\n",
       "      <td>0.227196</td>\n",
       "      <td>0.344463</td>\n",
       "      <td>0.769037</td>\n",
       "      <td>0.335538</td>\n",
       "      <td>0.152330</td>\n",
       "      <td>-0.110043</td>\n",
       "      <td>-0.164808</td>\n",
       "      <td>0.274283</td>\n",
       "      <td>1.121516</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.647084</td>\n",
       "      <td>0.667784</td>\n",
       "      <td>0.783456</td>\n",
       "      <td>0.838776</td>\n",
       "      <td>0.730886</td>\n",
       "      <td>0.652456</td>\n",
       "      <td>-0.404199</td>\n",
       "      <td>-0.214977</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0.316953</td>\n",
       "      <td>0.112573</td>\n",
       "      <td>0.056919</td>\n",
       "      <td>-0.195765</td>\n",
       "      <td>-0.199541</td>\n",
       "      <td>-1.423814</td>\n",
       "      <td>0.354501</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.217561</td>\n",
       "      <td>0.294265</td>\n",
       "      <td>0.388641</td>\n",
       "      <td>0.412349</td>\n",
       "      <td>0.525766</td>\n",
       "      <td>0.387468</td>\n",
       "      <td>-0.788069</td>\n",
       "      <td>-0.672306</td>\n",
       "      <td>-0.717335</td>\n",
       "      <td>-0.468311</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-1.685874</td>\n",
       "      <td>0.844102</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.217561</td>\n",
       "      <td>0.252763</td>\n",
       "      <td>0.257036</td>\n",
       "      <td>0.412349</td>\n",
       "      <td>0.423205</td>\n",
       "      <td>0.519962</td>\n",
       "      <td>-0.611364</td>\n",
       "      <td>-0.748027</td>\n",
       "      <td>-0.553410</td>\n",
       "      <td>-0.385760</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-0.726781</td>\n",
       "      <td>1.020775</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>-3.353309</td>\n",
       "      <td>-0.368153</td>\n",
       "      <td>-0.328267</td>\n",
       "      <td>-0.269384</td>\n",
       "      <td>-0.250982</td>\n",
       "      <td>-0.192155</td>\n",
       "      <td>-0.341250</td>\n",
       "      <td>-0.832165</td>\n",
       "      <td>-0.647154</td>\n",
       "      <td>-0.611553</td>\n",
       "      <td>-0.468311</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>0.660794</td>\n",
       "      <td>1.736277</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-1.266248</td>\n",
       "      <td>-1.282817</td>\n",
       "      <td>-1.278356</td>\n",
       "      <td>-1.245979</td>\n",
       "      <td>-1.371597</td>\n",
       "      <td>-1.334957</td>\n",
       "      <td>-0.742681</td>\n",
       "      <td>-0.629372</td>\n",
       "      <td>-0.646998</td>\n",
       "      <td>-0.429963</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>1.893715</td>\n",
       "      <td>-2.082856</td>\n",
       "      <td>1.405048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.641486</td>\n",
       "      <td>-0.660284</td>\n",
       "      <td>-0.751936</td>\n",
       "      <td>-0.819552</td>\n",
       "      <td>-0.807516</td>\n",
       "      <td>-0.738733</td>\n",
       "      <td>0.044394</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>-0.220841</td>\n",
       "      <td>-0.341734</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-0.825130</td>\n",
       "      <td>0.466169</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>1.584226</td>\n",
       "      <td>1.580832</td>\n",
       "      <td>1.660822</td>\n",
       "      <td>1.833773</td>\n",
       "      <td>1.807768</td>\n",
       "      <td>1.712410</td>\n",
       "      <td>-0.717670</td>\n",
       "      <td>-0.603596</td>\n",
       "      <td>-0.677184</td>\n",
       "      <td>-0.442866</td>\n",
       "      <td>-0.216410</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>1.346023</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quality  prescreen       ma2       ma3       ma4       ma5       ma6  \\\n",
       "0  0.059054   0.298213 -0.641486 -0.618782 -0.576463 -0.630029 -0.551116   \n",
       "1  0.059054   0.298213 -0.563391 -0.535778 -0.576463 -0.677410 -0.653676   \n",
       "2  0.059054   0.298213  0.920417  0.958299  1.046665  1.028299  0.936006   \n",
       "3  0.059054   0.298213  0.647084  0.667784  0.783456  0.838776  0.730886   \n",
       "4  0.059054   0.298213  0.217561  0.294265  0.388641  0.412349  0.525766   \n",
       "5  0.059054   0.298213  0.217561  0.252763  0.257036  0.412349  0.423205   \n",
       "6  0.059054  -3.353309 -0.368153 -0.328267 -0.269384 -0.250982 -0.192155   \n",
       "7  0.059054   0.298213 -1.266248 -1.282817 -1.278356 -1.245979 -1.371597   \n",
       "8  0.059054   0.298213 -0.641486 -0.660284 -0.751936 -0.819552 -0.807516   \n",
       "9  0.059054   0.298213  1.584226  1.580832  1.660822  1.833773  1.807768   \n",
       "\n",
       "        ma7  exudate8  exudate9  exudate10  exudate11  exudate12  exudate13  \\\n",
       "0 -0.473745 -0.242917 -0.246003  -0.296966  -0.271509  -0.218324  -0.194409   \n",
       "1 -0.539992 -0.109250  0.032972  -0.465224  -0.408593  -0.224256  -0.197212   \n",
       "2  0.784951 -0.141383  0.227196   0.344463   0.769037   0.335538   0.152330   \n",
       "3  0.652456 -0.404199 -0.214977   0.035830   0.316953   0.112573   0.056919   \n",
       "4  0.387468 -0.788069 -0.672306  -0.717335  -0.468311  -0.225828  -0.200905   \n",
       "5  0.519962 -0.611364 -0.748027  -0.553410  -0.385760  -0.225828  -0.200905   \n",
       "6 -0.341250 -0.832165 -0.647154  -0.611553  -0.468311  -0.225828  -0.200905   \n",
       "7 -1.334957 -0.742681 -0.629372  -0.646998  -0.429963  -0.225828  -0.200905   \n",
       "8 -0.738733  0.044394  0.021189  -0.220841  -0.341734  -0.225828  -0.200905   \n",
       "9  1.712410 -0.717670 -0.603596  -0.677184  -0.442866  -0.216410  -0.200905   \n",
       "\n",
       "   exudate14  exudate15    euDist  diameter  amfm_class  \n",
       "0  -0.205124  -0.186169 -1.294763 -0.468656    1.405048  \n",
       "1  -0.205175  -0.186281 -0.082168  2.006054   -0.711719  \n",
       "2  -0.110043  -0.164808  0.274283  1.121516   -0.711719  \n",
       "3  -0.195765  -0.199541 -1.423814  0.354501   -0.711719  \n",
       "4  -0.214968  -0.208100 -1.685874  0.844102   -0.711719  \n",
       "5  -0.214968  -0.208100 -0.726781  1.020775   -0.711719  \n",
       "6  -0.214968  -0.208100  0.660794  1.736277   -0.711719  \n",
       "7  -0.214968  -0.208100  1.893715 -2.082856    1.405048  \n",
       "8  -0.214968  -0.208100 -0.825130  0.466169   -0.711719  \n",
       "9  -0.214968  -0.208100  1.346023  0.039176   -0.711719  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "scaler = StandardScaler()\n",
    "features[['quality', 'prescreen', 'ma2', 'ma3', 'ma4', 'ma5', 'ma6', 'ma7', 'exudate8', 'exudate9', 'exudate10', 'exudate11', 'exudate12', 'exudate13', 'exudate14', 'exudate15', 'euDist', 'diameter', 'amfm_class']] = scaler.fit_transform(features[['quality', 'prescreen', 'ma2', 'ma3', 'ma4', 'ma5', 'ma6', 'ma7', 'exudate8', 'exudate9', 'exudate10', 'exudate11', 'exudate12', 'exudate13', 'exudate14', 'exudate15', 'euDist', 'diameter', 'amfm_class']])\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3 . Split your dataset into training and test sets (80% - 20% split). Use `sklearn.model_selection.train_test_split` to help you in this task. You should be working with your standardized features from here forward. Display how many records are in the training set and how many are in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in training set: 920\n",
      "Number of records in test set: 231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>prescreen</th>\n",
       "      <th>ma2</th>\n",
       "      <th>ma3</th>\n",
       "      <th>ma4</th>\n",
       "      <th>ma5</th>\n",
       "      <th>ma6</th>\n",
       "      <th>ma7</th>\n",
       "      <th>exudate8</th>\n",
       "      <th>exudate9</th>\n",
       "      <th>exudate10</th>\n",
       "      <th>exudate11</th>\n",
       "      <th>exudate12</th>\n",
       "      <th>exudate13</th>\n",
       "      <th>exudate14</th>\n",
       "      <th>exudate15</th>\n",
       "      <th>euDist</th>\n",
       "      <th>diameter</th>\n",
       "      <th>amfm_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.641486</td>\n",
       "      <td>-0.618782</td>\n",
       "      <td>-0.576463</td>\n",
       "      <td>-0.630029</td>\n",
       "      <td>-0.551116</td>\n",
       "      <td>-0.473745</td>\n",
       "      <td>-0.242917</td>\n",
       "      <td>-0.246003</td>\n",
       "      <td>-0.296966</td>\n",
       "      <td>-0.271509</td>\n",
       "      <td>-0.218324</td>\n",
       "      <td>-0.194409</td>\n",
       "      <td>-0.205124</td>\n",
       "      <td>-0.186169</td>\n",
       "      <td>-1.294763</td>\n",
       "      <td>-0.468656</td>\n",
       "      <td>1.405048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.563391</td>\n",
       "      <td>-0.535778</td>\n",
       "      <td>-0.576463</td>\n",
       "      <td>-0.677410</td>\n",
       "      <td>-0.653676</td>\n",
       "      <td>-0.539992</td>\n",
       "      <td>-0.109250</td>\n",
       "      <td>0.032972</td>\n",
       "      <td>-0.465224</td>\n",
       "      <td>-0.408593</td>\n",
       "      <td>-0.224256</td>\n",
       "      <td>-0.197212</td>\n",
       "      <td>-0.205175</td>\n",
       "      <td>-0.186281</td>\n",
       "      <td>-0.082168</td>\n",
       "      <td>2.006054</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.920417</td>\n",
       "      <td>0.958299</td>\n",
       "      <td>1.046665</td>\n",
       "      <td>1.028299</td>\n",
       "      <td>0.936006</td>\n",
       "      <td>0.784951</td>\n",
       "      <td>-0.141383</td>\n",
       "      <td>0.227196</td>\n",
       "      <td>0.344463</td>\n",
       "      <td>0.769037</td>\n",
       "      <td>0.335538</td>\n",
       "      <td>0.152330</td>\n",
       "      <td>-0.110043</td>\n",
       "      <td>-0.164808</td>\n",
       "      <td>0.274283</td>\n",
       "      <td>1.121516</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.647084</td>\n",
       "      <td>0.667784</td>\n",
       "      <td>0.783456</td>\n",
       "      <td>0.838776</td>\n",
       "      <td>0.730886</td>\n",
       "      <td>0.652456</td>\n",
       "      <td>-0.404199</td>\n",
       "      <td>-0.214977</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0.316953</td>\n",
       "      <td>0.112573</td>\n",
       "      <td>0.056919</td>\n",
       "      <td>-0.195765</td>\n",
       "      <td>-0.199541</td>\n",
       "      <td>-1.423814</td>\n",
       "      <td>0.354501</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.217561</td>\n",
       "      <td>0.294265</td>\n",
       "      <td>0.388641</td>\n",
       "      <td>0.412349</td>\n",
       "      <td>0.525766</td>\n",
       "      <td>0.387468</td>\n",
       "      <td>-0.788069</td>\n",
       "      <td>-0.672306</td>\n",
       "      <td>-0.717335</td>\n",
       "      <td>-0.468311</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-1.685874</td>\n",
       "      <td>0.844102</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>0.217561</td>\n",
       "      <td>0.252763</td>\n",
       "      <td>0.257036</td>\n",
       "      <td>0.412349</td>\n",
       "      <td>0.423205</td>\n",
       "      <td>0.519962</td>\n",
       "      <td>-0.611364</td>\n",
       "      <td>-0.748027</td>\n",
       "      <td>-0.553410</td>\n",
       "      <td>-0.385760</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-0.726781</td>\n",
       "      <td>1.020775</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>-3.353309</td>\n",
       "      <td>-0.368153</td>\n",
       "      <td>-0.328267</td>\n",
       "      <td>-0.269384</td>\n",
       "      <td>-0.250982</td>\n",
       "      <td>-0.192155</td>\n",
       "      <td>-0.341250</td>\n",
       "      <td>-0.832165</td>\n",
       "      <td>-0.647154</td>\n",
       "      <td>-0.611553</td>\n",
       "      <td>-0.468311</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>0.660794</td>\n",
       "      <td>1.736277</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-1.266248</td>\n",
       "      <td>-1.282817</td>\n",
       "      <td>-1.278356</td>\n",
       "      <td>-1.245979</td>\n",
       "      <td>-1.371597</td>\n",
       "      <td>-1.334957</td>\n",
       "      <td>-0.742681</td>\n",
       "      <td>-0.629372</td>\n",
       "      <td>-0.646998</td>\n",
       "      <td>-0.429963</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>1.893715</td>\n",
       "      <td>-2.082856</td>\n",
       "      <td>1.405048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>-0.641486</td>\n",
       "      <td>-0.660284</td>\n",
       "      <td>-0.751936</td>\n",
       "      <td>-0.819552</td>\n",
       "      <td>-0.807516</td>\n",
       "      <td>-0.738733</td>\n",
       "      <td>0.044394</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>-0.220841</td>\n",
       "      <td>-0.341734</td>\n",
       "      <td>-0.225828</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>-0.825130</td>\n",
       "      <td>0.466169</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.059054</td>\n",
       "      <td>0.298213</td>\n",
       "      <td>1.584226</td>\n",
       "      <td>1.580832</td>\n",
       "      <td>1.660822</td>\n",
       "      <td>1.833773</td>\n",
       "      <td>1.807768</td>\n",
       "      <td>1.712410</td>\n",
       "      <td>-0.717670</td>\n",
       "      <td>-0.603596</td>\n",
       "      <td>-0.677184</td>\n",
       "      <td>-0.442866</td>\n",
       "      <td>-0.216410</td>\n",
       "      <td>-0.200905</td>\n",
       "      <td>-0.214968</td>\n",
       "      <td>-0.208100</td>\n",
       "      <td>1.346023</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>-0.711719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quality  prescreen       ma2       ma3       ma4       ma5       ma6  \\\n",
       "0  0.059054   0.298213 -0.641486 -0.618782 -0.576463 -0.630029 -0.551116   \n",
       "1  0.059054   0.298213 -0.563391 -0.535778 -0.576463 -0.677410 -0.653676   \n",
       "2  0.059054   0.298213  0.920417  0.958299  1.046665  1.028299  0.936006   \n",
       "3  0.059054   0.298213  0.647084  0.667784  0.783456  0.838776  0.730886   \n",
       "4  0.059054   0.298213  0.217561  0.294265  0.388641  0.412349  0.525766   \n",
       "5  0.059054   0.298213  0.217561  0.252763  0.257036  0.412349  0.423205   \n",
       "6  0.059054  -3.353309 -0.368153 -0.328267 -0.269384 -0.250982 -0.192155   \n",
       "7  0.059054   0.298213 -1.266248 -1.282817 -1.278356 -1.245979 -1.371597   \n",
       "8  0.059054   0.298213 -0.641486 -0.660284 -0.751936 -0.819552 -0.807516   \n",
       "9  0.059054   0.298213  1.584226  1.580832  1.660822  1.833773  1.807768   \n",
       "\n",
       "        ma7  exudate8  exudate9  exudate10  exudate11  exudate12  exudate13  \\\n",
       "0 -0.473745 -0.242917 -0.246003  -0.296966  -0.271509  -0.218324  -0.194409   \n",
       "1 -0.539992 -0.109250  0.032972  -0.465224  -0.408593  -0.224256  -0.197212   \n",
       "2  0.784951 -0.141383  0.227196   0.344463   0.769037   0.335538   0.152330   \n",
       "3  0.652456 -0.404199 -0.214977   0.035830   0.316953   0.112573   0.056919   \n",
       "4  0.387468 -0.788069 -0.672306  -0.717335  -0.468311  -0.225828  -0.200905   \n",
       "5  0.519962 -0.611364 -0.748027  -0.553410  -0.385760  -0.225828  -0.200905   \n",
       "6 -0.341250 -0.832165 -0.647154  -0.611553  -0.468311  -0.225828  -0.200905   \n",
       "7 -1.334957 -0.742681 -0.629372  -0.646998  -0.429963  -0.225828  -0.200905   \n",
       "8 -0.738733  0.044394  0.021189  -0.220841  -0.341734  -0.225828  -0.200905   \n",
       "9  1.712410 -0.717670 -0.603596  -0.677184  -0.442866  -0.216410  -0.200905   \n",
       "\n",
       "   exudate14  exudate15    euDist  diameter  amfm_class  \n",
       "0  -0.205124  -0.186169 -1.294763 -0.468656    1.405048  \n",
       "1  -0.205175  -0.186281 -0.082168  2.006054   -0.711719  \n",
       "2  -0.110043  -0.164808  0.274283  1.121516   -0.711719  \n",
       "3  -0.195765  -0.199541 -1.423814  0.354501   -0.711719  \n",
       "4  -0.214968  -0.208100 -1.685874  0.844102   -0.711719  \n",
       "5  -0.214968  -0.208100 -0.726781  1.020775   -0.711719  \n",
       "6  -0.214968  -0.208100  0.660794  1.736277   -0.711719  \n",
       "7  -0.214968  -0.208100  1.893715 -2.082856    1.405048  \n",
       "8  -0.214968  -0.208100 -0.825130  0.466169   -0.711719  \n",
       "9  -0.214968  -0.208100  1.346023  0.039176   -0.711719  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "training, test = train_test_split(features, train_size = 0.8, test_size = 0.2, shuffle=False)\n",
    "training_label, test_label = train_test_split(label, train_size = 0.8, test_size = 0.2, shuffle=False)\n",
    "print('Number of records in training set:', len(training))\n",
    "print('Number of records in test set:', len(test))\n",
    "training.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. PCA is affected by the scale of the features that is why it is important to standardize the dataset first. The principle components generated by PCA are sensitive to the shape of the data in d-dimensional space. \n",
    "* Carry out a principal components analysis using `sklearn.decomposition.PCA` Note that you are fitting PCA on the **training set** only (NOT the test set).\n",
    "* Use the `pca.explained_variance_ratio_` field to determine how many principal components are needed so that 95% variance is retained. \n",
    "* Reduce the PCA-transformed-dataset to this number of columns and you'll use the resulting dataset for subsequent tasks.\n",
    "\n",
    "* Once the training set's dimensionality has been reduced with PCA, transform the **test set** to the principal component space that was created. (Do not fit a new PCA. Use the same one that was created with the training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36938152 0.55733449 0.65734314 0.73249252 0.80189611 0.85823555\n",
      " 0.90546263 0.94745189 0.96681907]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.782451</td>\n",
       "      <td>-1.184018</td>\n",
       "      <td>0.138917</td>\n",
       "      <td>0.176886</td>\n",
       "      <td>-0.732953</td>\n",
       "      <td>-0.464039</td>\n",
       "      <td>0.790600</td>\n",
       "      <td>-0.068067</td>\n",
       "      <td>0.104059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.631122</td>\n",
       "      <td>-1.474183</td>\n",
       "      <td>0.741414</td>\n",
       "      <td>0.147735</td>\n",
       "      <td>-0.221243</td>\n",
       "      <td>-0.379892</td>\n",
       "      <td>0.798630</td>\n",
       "      <td>-1.537102</td>\n",
       "      <td>0.519236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.027680</td>\n",
       "      <td>1.295162</td>\n",
       "      <td>0.289986</td>\n",
       "      <td>-0.200816</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.451751</td>\n",
       "      <td>0.796846</td>\n",
       "      <td>0.831317</td>\n",
       "      <td>0.640055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.504802</td>\n",
       "      <td>-0.519017</td>\n",
       "      <td>0.015586</td>\n",
       "      <td>-0.133559</td>\n",
       "      <td>0.464030</td>\n",
       "      <td>-0.507388</td>\n",
       "      <td>-0.830339</td>\n",
       "      <td>-1.084029</td>\n",
       "      <td>0.187537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.665369</td>\n",
       "      <td>-1.800169</td>\n",
       "      <td>0.708893</td>\n",
       "      <td>-0.281202</td>\n",
       "      <td>0.467406</td>\n",
       "      <td>0.123287</td>\n",
       "      <td>1.396495</td>\n",
       "      <td>0.499691</td>\n",
       "      <td>0.257153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.272150</td>\n",
       "      <td>-0.811509</td>\n",
       "      <td>0.762688</td>\n",
       "      <td>0.108362</td>\n",
       "      <td>-1.051412</td>\n",
       "      <td>-0.826547</td>\n",
       "      <td>0.339325</td>\n",
       "      <td>0.047743</td>\n",
       "      <td>0.039572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.377188</td>\n",
       "      <td>-1.188423</td>\n",
       "      <td>-0.036172</td>\n",
       "      <td>-0.016591</td>\n",
       "      <td>0.120869</td>\n",
       "      <td>-0.076164</td>\n",
       "      <td>0.726961</td>\n",
       "      <td>0.038806</td>\n",
       "      <td>0.138049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.745853</td>\n",
       "      <td>0.318283</td>\n",
       "      <td>-0.390134</td>\n",
       "      <td>0.056092</td>\n",
       "      <td>0.241641</td>\n",
       "      <td>-0.194151</td>\n",
       "      <td>0.068513</td>\n",
       "      <td>-0.838229</td>\n",
       "      <td>-0.129914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.126825</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>0.043997</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>-0.235642</td>\n",
       "      <td>-0.664486</td>\n",
       "      <td>-0.325941</td>\n",
       "      <td>-0.895302</td>\n",
       "      <td>0.129376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.495017</td>\n",
       "      <td>-0.383906</td>\n",
       "      <td>-0.004248</td>\n",
       "      <td>-0.260710</td>\n",
       "      <td>-0.398199</td>\n",
       "      <td>-0.807200</td>\n",
       "      <td>-0.534848</td>\n",
       "      <td>1.172038</td>\n",
       "      <td>0.012874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.782451 -1.184018  0.138917  0.176886 -0.732953 -0.464039  0.790600   \n",
       "1 -1.631122 -1.474183  0.741414  0.147735 -0.221243 -0.379892  0.798630   \n",
       "2  1.027680  1.295162  0.289986 -0.200816  0.832564  0.451751  0.796846   \n",
       "3 -1.504802 -0.519017  0.015586 -0.133559  0.464030 -0.507388 -0.830339   \n",
       "4 -0.665369 -1.800169  0.708893 -0.281202  0.467406  0.123287  1.396495   \n",
       "5  1.272150 -0.811509  0.762688  0.108362 -1.051412 -0.826547  0.339325   \n",
       "6  2.377188 -1.188423 -0.036172 -0.016591  0.120869 -0.076164  0.726961   \n",
       "7 -2.745853  0.318283 -0.390134  0.056092  0.241641 -0.194151  0.068513   \n",
       "8 -3.126825 -0.257464  0.043997  0.048387 -0.235642 -0.664486 -0.325941   \n",
       "9 -2.495017 -0.383906 -0.004248 -0.260710 -0.398199 -0.807200 -0.534848   \n",
       "\n",
       "          7         8  \n",
       "0 -0.068067  0.104059  \n",
       "1 -1.537102  0.519236  \n",
       "2  0.831317  0.640055  \n",
       "3 -1.084029  0.187537  \n",
       "4  0.499691  0.257153  \n",
       "5  0.047743  0.039572  \n",
       "6  0.038806  0.138049  \n",
       "7 -0.838229 -0.129914  \n",
       "8 -0.895302  0.129376  \n",
       "9  1.172038  0.012874  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 0.95, svd_solver='full')\n",
    "pca.fit(training)\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "pca_training = pd.DataFrame(pca.transform(training))\n",
    "pca_test = pd.DataFrame(pca.transform(test))\n",
    "pca_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training Decision Trees in `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Use `sklearn.tree.DecisionTreeClassifier` to fit a decision tree classifier on the training set. Use entropy as the split criterion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree = tree.fit(pca_training, training_label)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Now that the tree has been learned from the training data, we can run the test data through and predict classes for our test data. Use the `predict` method of `DecisionTreeClassifier` to classify the test data. Then use `sklearn.metrics.accuracy_score` to print out the accuracy of the classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5584415584415584\n",
      "0.5584415584415584\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predicted_labels = tree.predict(pca_test)\n",
    "accuracy = accuracy_score(test_label, predicted_labels, normalize=True)\n",
    "score = tree.score(pca_test, test_label)\n",
    "print(score)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Note that the DecisionTree classifier has many parameters that can be set. Try tweaking parameters like split criterion, max_depth, min_impurity_decrease, min_samples_leaf, min_samples_split, etc. to see how they affect accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5800865800865801"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "other_tree = DecisionTreeClassifier(criterion='gini', max_depth=1, min_impurity_decrease=0, min_samples_leaf=1, min_samples_split=2)\n",
    "other_tree = other_tree.fit(pca_training, training_label)\n",
    "other_predicted_labels = other_tree.predict(pca_test)\n",
    "other_accuracy = accuracy_score(test_label, other_predicted_labels, normalize=True)\n",
    "other_accuracy\n",
    "#Tried a bunch of different values for those paramenters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using K-fold Cross Validation\n",
    "\n",
    "You have now built a decision tree and tested it's accuracy using the \"holdout\" method. But as discussed in class, this is not sufficient for estimating generalization accuracy. Instead, we should use Cross Validation to get a better estimate of accuracy. You will do that next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Use `sklearn.model_selection.cross_val_score` to perform 10-fold cross validation on your decision tree. Report the accuracy of the model. For this step, revert back to using the data before it underwent PCA. So you want to use the standardized data that came out of Q2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60344828 0.59130435 0.64347826 0.6173913  0.6        0.62608696\n",
      " 0.60869565 0.6        0.66956522 0.60869565]\n",
      "0.6168665667166418\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "tree_new = DecisionTreeClassifier(criterion='entropy')\n",
    "scores = cross_val_score(tree_new, features, label, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Now we want to tune our model to use the best parameters to avoid overfitting to our training data. Grid search is an approach to parameter tuning that will methodically build and evaluate a model for each combination of algorithm parameters specified in a grid. \n",
    "* Use `sklearn.model_selection.GridSearchCV` to find the best `max_depth`, `max_features`, and `min_samples_leaf` for your tree. Use 'accuracy' for the scoring criteria.\n",
    "* Try the values [5,10,15,20] for `max_depth` and `min_samples_leaf`. Try [5,10,15] for `max_features`. \n",
    "* Use a 5-fold cross validation. \n",
    "* Print out the best value for each of the tested parameters.\n",
    "* Print out the accuracy of the model with these best values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'max_features': 15, 'min_samples_leaf': 15}\n",
      "0.6507384882710686\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':[5,10,15,20], 'min_samples_leaf':[5,10,15,20], 'max_features':[5,10,15]}\n",
    "tune = GridSearchCV(tree_new, param_grid=parameters, scoring='accuracy', cv=5)\n",
    "tune.fit(features, label)\n",
    "print(tune.best_params_)\n",
    "print(tune.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. To perform the nested cross-validation that we discussed in class, you'll now need to pass the `GridSearchCV` into a `cross_val_score`. \n",
    "\n",
    "What this does is: the `cross_val_score` splits the data in to train and test sets for the first fold, and it passes the train set into `GridSearchCV`. `GridSearchCV` then splits that set into train and validation sets for k number of folds (the inner CV loop). The hyper-parameters for which the average score over all inner iterations is best, is reported as the `best_params_`, `best_score_`, and `best_estimator_`(best decision tree). This best decision tree is then evaluated with the test set from the `cross_val_score` (the outer CV loop). And this whole thing is repeated for the remaining k folds of the `cross_val_score` (the outer CV loop). \n",
    "\n",
    "That is a lot of explanation for a very complex (but IMPORTANT) process, which can all be performed with a single line of code!\n",
    "\n",
    "Be patient for this one to run. The nested cross-validation loop can take some time. An asterisk [\\*] next to the cell indicates that it is still running.\n",
    "\n",
    "Print the accuracy of your tuned, cross-validated model. This is the official accuracy that you would report for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6350899550224887"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here\n",
    "cross_val_score(tune, features, label, cv=10)\n",
    "cross_val_score(tune, features, label, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. Our accuracy rate isn't very good. We wouldn't want to use this model in the real world to actually diagnose patients because it is wrong about 40% of the time! What can we do to improve the accuracy of the model? Answer as a comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGive more data points to train on\\nPost-prune the tree\\nSet the max depth of the tree to where the validation error is the smallest\\nIf two features are highly correlated, then get rid of one of them\\nAny method that can do a dimensionality reduction\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Give more data points to train on\n",
    "Post-prune the tree\n",
    "Set the max depth of the tree to where the validation error is the smallest\n",
    "If two features are highly correlated, then get rid of one of them\n",
    "Any method that can do a dimensionality reduction\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
